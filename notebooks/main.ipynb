{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2293a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import signal\n",
    "import atexit\n",
    "import pandas as pd\n",
    "import docx\n",
    "import fitz\n",
    "import cv2\n",
    "import pytesseract\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, Image\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.schema import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "# Load Groq API key\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"Groq_API_KEY\")\n",
    "if not GROQ_API_KEY:\n",
    "    raise ValueError(\"Groq_API_KEY not found in .env file\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3e9449ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(file_name):\n",
    "    _, ext = os.path.splitext(file_name)\n",
    "    ext = ext.lower()\n",
    "    if ext == \".pdf\": return \"pdf\"\n",
    "    elif ext == \".docx\": return \"docx\"\n",
    "    elif ext == \".csv\": return \"csv\"\n",
    "    elif ext in [\".xls\", \".xlsx\"]: return \"excel\"\n",
    "    elif ext in [\".png\", \".jpg\", \".jpeg\"]: return \"image\"\n",
    "    else: raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "def read_file_as_text(file_path):\n",
    "    doc_type = load_document(file_path)\n",
    "    \n",
    "    if doc_type == \"pdf\":\n",
    "        text = \"\"\n",
    "        with fitz.open(file_path) as pdf:\n",
    "            for page in pdf:\n",
    "                text += page.get_text()\n",
    "        return text\n",
    "    elif doc_type == \"docx\":\n",
    "        doc = docx.Document(file_path)\n",
    "        return \"\\n\".join([p.text for p in doc.paragraphs])\n",
    "    elif doc_type == \"csv\":\n",
    "        df = pd.read_csv(file_path)\n",
    "        return \"\\n\".join([\", \".join(map(str, row)) for row in df.values])\n",
    "    elif doc_type == \"excel\":\n",
    "        df = pd.read_excel(file_path)\n",
    "        return \"\\n\".join([\", \".join(map(str, row)) for row in df.values])\n",
    "    elif doc_type == \"image\":\n",
    "        img = cv2.imread(file_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image not found: {file_path}\")\n",
    "\n",
    "        # --- Preprocessing ---\n",
    "        def preprocess(image):\n",
    "            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "            blur = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "            _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "            return thresh\n",
    "\n",
    "        # --- OCR function ---\n",
    "        def ocr_find(image):\n",
    "            config = '--oem 3 --psm 6'\n",
    "            return pytesseract.image_to_string(image, config=config)\n",
    "\n",
    "        img_preprocessed = preprocess(img)\n",
    "        text = ocr_find(img_preprocessed)\n",
    "\n",
    "        #print(\"Detected text:\\n\", text)\n",
    "        return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0e08031",
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DIR = 'vectorstore'\n",
    "VECTOR_DB = os.path.join(VECTOR_DIR, 'db_faiss')\n",
    "\n",
    "def cleanup_embeddings():\n",
    "    if os.path.exists(VECTOR_DIR):\n",
    "        shutil.rmtree(VECTOR_DIR)\n",
    "        print(\"Old embeddings deleted.\")\n",
    "\n",
    "def handle_signal(signum, frame):\n",
    "    print(f\"\\nSignal {signum} received! Cleaning up embeddings...\")\n",
    "    cleanup_embeddings()\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, handle_signal)\n",
    "signal.signal(signal.SIGTERM, handle_signal)\n",
    "atexit.register(cleanup_embeddings)\n",
    "\n",
    "def convert_to_vector(all_content):\n",
    "    if not os.path.exists(VECTOR_DIR):\n",
    "        os.makedirs(VECTOR_DIR)\n",
    "\n",
    "    if os.path.exists(VECTOR_DB):\n",
    "        print(\"Loading existing vectorstore...\")\n",
    "        vector_store = FAISS.load_local(\n",
    "            VECTOR_DB,\n",
    "            HuggingFaceEmbeddings(\n",
    "                model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "                model_kwargs={'device': 'cpu'}\n",
    "            ),\n",
    "            allow_dangerous_deserialization=True\n",
    "        )\n",
    "    else:\n",
    "        splitter = RecursiveCharacterTextSplitter(\n",
    "            separators=[\"\\n\\n\",\"\\n\",\" \"],\n",
    "            chunk_size=3000,\n",
    "            chunk_overlap=50\n",
    "        )\n",
    "        all_chunks = []\n",
    "        for doc in all_content:\n",
    "            chunks = splitter.split_text(doc.page_content)\n",
    "            all_chunks.extend(chunks)\n",
    "        \n",
    "        embeddings = HuggingFaceEmbeddings(\n",
    "            model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "            model_kwargs={'device': 'cpu'}\n",
    "        )\n",
    "        vector_store = FAISS.from_texts(all_chunks, embeddings)\n",
    "        vector_store.save_local(VECTOR_DB)\n",
    "        print(\"Vector store created and saved.\")\n",
    "    return vector_store\n",
    "\n",
    "def find_relevant_chunk(query, vector_store, top_k=100):\n",
    "    return vector_store.similarity_search(query, k=top_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "8cfbd865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59495e2cebca498e8574aba0443c5c5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.pdf,.docx,.csv,.xls,.xlsx,.png,.jpg,.jpeg', description='Upload', multiple=True)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mikey = Groq(api_key=GROQ_API_KEY)\n",
    "\n",
    "prompt_template_string = \"\"\"\n",
    "You are a lightweight assistant. Ground answers in the context provided. \n",
    "If answer not found, say: “I don't know from the current knowledge base.” \n",
    "Context: {context} \n",
    "Question: {question} \n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"], \n",
    "    template=prompt_template_string\n",
    ")\n",
    "\n",
    "class GroqLLM:\n",
    "    def __init__(self, client, prompt_template, model=\"llama-3.1-8b-instant\"):\n",
    "        self.client = client\n",
    "        self.model = model\n",
    "        self.prompt_template = prompt_template\n",
    "\n",
    "    def __call__(self, inputs: dict) -> str:\n",
    "        prompt_text = self.prompt_template.format(**inputs)\n",
    "        response = self.client.chat.completions.create(\n",
    "            model=self.model,\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt_text}],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7,\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "\n",
    "llm = GroqLLM(mikey, prompt)\n",
    "rag_chain = llm | StrOutputParser()\n",
    "\n",
    "def call_llm(query: str, context: str) -> str:\n",
    "    inputs = {\"context\": context, \"question\": query}\n",
    "    try:\n",
    "        return rag_chain.invoke(input=inputs)\n",
    "    except Exception as e:\n",
    "        print(\"Groq API error:\", e)\n",
    "        return \"Error generating response.\"\n",
    "\n",
    "import tempfile\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "uploader = widgets.FileUpload(\n",
    "    accept='.pdf,.docx,.csv,.xls,.xlsx,.png,.jpg,.jpeg', \n",
    "    multiple=True\n",
    ")\n",
    "display(uploader)\n",
    "\n",
    "all_content = []\n",
    "\n",
    "def process_upload(change):\n",
    "    all_content.clear()\n",
    "    for uploaded_file in uploader.value:\n",
    "        filename = uploaded_file.name\n",
    "        print(f\"Processing: {filename}\")\n",
    "        ext = os.path.splitext(filename)[1]\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:\n",
    "            tmp.write(uploaded_file.content)\n",
    "            tmp_path = tmp.name\n",
    "        try:\n",
    "            text = read_file_as_text(tmp_path)\n",
    "            all_content.append(Document(page_content=text))\n",
    "            print(\"ext extracted (first 500 chars):\\n\", text[:500])\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {filename}: {e}\")\n",
    "        finally:\n",
    "            os.remove(tmp_path)\n",
    "\n",
    "uploader.observe(process_upload, names='value')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "ce75eb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ed9552863f4c74b2c295be23ebdfc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='process', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_store = None\n",
    "\n",
    "def init_vector_store(_):\n",
    "    global vector_store\n",
    "    if not all_content:\n",
    "        print(\"No files uploaded yet.\")\n",
    "        return\n",
    "    vector_store = convert_to_vector(all_content)\n",
    "    print(\"Vector store ready.\")\n",
    "\n",
    "btn_vector = widgets.Button(description=\"process\")\n",
    "btn_vector.on_click(init_vector_store)\n",
    "display(btn_vector)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c420450",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "970deaa19ae94d6ea3e455cdf3ba2012",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', continuous_update=False, description='Query:', layout=Layout(width='80%'), placeholder='Type yo…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a941938d364d47a27dc8efd3d00292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- Query box ---\n",
    "query_box = widgets.Text(\n",
    "    placeholder='Type your question here...',\n",
    "    description='Query:',\n",
    "    style={'description_width': 'initial'},\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "# --- Output widget ---\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# --- Scrollable display function ---\n",
    "def display_scrollable_answer(answer, width='1000px', height='300px'):\n",
    "    display(HTML(f\"\"\"\n",
    "    <div style=\"\n",
    "        width:{width};\n",
    "        height:{height};\n",
    "        overflow:auto;\n",
    "        white-space:pre-wrap;\n",
    "        border:1px solid #ccc;\n",
    "        padding:10px;\n",
    "        font-family:monospace;\n",
    "        background:#f9f9f9;\n",
    "    \">\n",
    "    {answer}\n",
    "    </div>\n",
    "    \"\"\"))\n",
    "\n",
    "# --- Query handling ---\n",
    "def run_query(change):\n",
    "    query = query_box.value.strip()\n",
    "    if not query:\n",
    "        return\n",
    "\n",
    "    with output_area:\n",
    "        output_area.clear_output()\n",
    "        print(f\"Query: {query}\\n\")\n",
    "        try:\n",
    "            context = find_relevant_chunk(query, vector_store)\n",
    "            answer = call_llm(query, context)\n",
    "            display_scrollable_answer(answer)  #scrollable output here\n",
    "        except Exception as e:\n",
    "            print(\"Error:\", e)\n",
    "\n",
    "# --- Use 'on_submit' replacement ---\n",
    "query_box.continuous_update = False\n",
    "query_box.observe(run_query, names='value')\n",
    "\n",
    "# --- Display UI ---\n",
    "display(query_box, output_area)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdf61bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "auto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
